{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Assgnment : Feature Engineering**"
      ],
      "metadata": {
        "id": "4CvxLRKzD2ms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.What is a parameter?**"
      ],
      "metadata": {
        "id": "kP7NPe62EE8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## -> In machine learning, a parameter is a variable that a model learns from the training data. Parameters define how the model makes predictions and are adjusted during training to minimize error."
      ],
      "metadata": {
        "id": "w478p5qjEJ1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. What is correlation?**\n",
        "# **What does negative correlation mean?**"
      ],
      "metadata": {
        "id": "caLJHOO2FEnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation measures the statistical relationship between two variables. It quantifies how strongly two variables are related and the direction of that relationship.\n",
        "\n",
        "## **Negative Correlation**: When two variables tend to move in opposite directions.\n",
        "## As one variable increases, the other variable tends to decrease.\n",
        "## **Example**: Temperature and ice cream sales. As the temperature increases, ice cream sales tend to increase."
      ],
      "metadata": {
        "id": "wYEkIpxIFTWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.Define Machine Learning. What are the main components in Machine Learning?**"
      ],
      "metadata": {
        "id": "a17SPjH4Fr7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning is a subfield of computer science it gives the ability to the computer to learn pattern from the data without explicitly programmed.\n",
        "\n",
        "## **Main Components of Machine Learning**\n",
        "## **Data**\n",
        "\n",
        "## -> The foundation of ML. Data can be structured (tables, databases) or unstructured (images, text).\n",
        "## -> Divided into training, validation, and testing datasets.\n",
        "## **Features**\n",
        "\n",
        "## -> Attributes or characteristics extracted from the data to help the model make predictions.\n",
        "## -> Feature engineering and selection are key to improving model performance.\n",
        "## **Model**\n",
        "\n",
        "## -> The mathematical structure (e.g., linear regression, decision tree, neural network) that processes input data to make predictions.\n",
        "## -> Different models are chosen based on the problem type (classification, regression, clustering).\n",
        "## **Algorithm**\n",
        "\n",
        "## Defines how the model learns from data. Common algorithms include:\n",
        "## -> Supervised Learning (e.g., Decision Trees, Support Vector Machines)\n",
        "## -> Unsupervised Learning (e.g., K-Means, PCA)\n",
        "## -> Reinforcement Learning (e.g., Q-learning, Deep Q Networks)"
      ],
      "metadata": {
        "id": "ENelHmOrHR2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. How does loss value help in determining whether the model is good or not?**"
      ],
      "metadata": {
        "id": "F7sHyxwPNQN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **How Loss Value Helps in Evaluating a Model**\n",
        "## The loss value is a numerical measure of how well (or poorly) a machine learning model is performing. It quantifies the difference between the model’s predictions and the actual values from the dataset. A lower loss value generally indicates a better model, whereas a higher loss value suggests poor performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "E7F_Fx-bNoMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.What are continuous and categorical variables?**"
      ],
      "metadata": {
        "id": "rLFcNQW0NyEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Continuous Variables**\n",
        "## -> A continuous variable can take an infinite number of values within a given range. These are typically numerical values that can be measured and have decimal precision.\n",
        "\n",
        "## Examples:\n",
        "## Height\n",
        "## Temperature\n",
        "## Price\n",
        "## Age\n",
        "\n",
        "## **2. Categorical Variables**\n",
        "## -> A categorical variable represents distinct groups or categories. These values are not numerical but instead belong to specific groups or labels.\n",
        "\n",
        "## Types of Categorical Variables:\n",
        "## **Nominal Variables (No inherent order)**\n",
        "## Examples: Gender (Male, Female, Other), Color (Red, Blue, Green)\n",
        "## **Ordinal Variables (Has an inherent order)**\n",
        "## Examples: Education Level (High School < Bachelor's < Master's < PhD), Customer Satisfaction (Low, Medium, High)"
      ],
      "metadata": {
        "id": "_f5OxuCJOHL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. How do we handle categorical variables in Machine Learning? What are the common techniques?**"
      ],
      "metadata": {
        "id": "HY_r4MheOtmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Categorical variables represent data that can take on a limited number of discrete values, such as \"color\" (red, blue, green), \"city\" (New York, Paris, London), or \"occupation\" (doctor, engineer, teacher).\n",
        "\n",
        "## Since most machine learning algorithms require numerical input, we need to convert these categorical values into a suitable numerical representation. Here are some common techniques:\n",
        "\n",
        "## **1. One-Hot Encoding:**\n",
        "\n",
        "## **Principle**: Creates new binary features (columns) for each category within a categorical variable.\n",
        "## **Example**: If the \"color\" feature has values \"red\", \"blue\", and \"green\", one-hot encoding would create three new binary features: \"color_red\", \"color_blue\", and \"color_green\". A data point with \"red\" as the color would have a value of 1 for \"color_red\" and 0 for the other two features.\n",
        "## **Advantages**: Simple to understand and implement. Preserves information about the absence or presence of a category.\n",
        "## **Disadvantages**: Can increase the dimensionality of the data significantly, especially with many categories.\n",
        "## **2. Label Encoding**:\n",
        "\n",
        "## **Principle**: Assigns a unique integer to each category.\n",
        "## **Example**: If the \"color\" feature has values \"red\", \"blue\", and \"green\", they might be assigned integers 0, 1, and 2 respectively.\n",
        "## **Advantages**: Simple to implement.\n",
        "## **Disadvantages**: Introduces an artificial order among the categories, which may not be meaningful. This can be problematic for some algorithms.\n",
        "## **3. Ordinal Encoding:**\n",
        "\n",
        "## **Principle**: Similar to label encoding, but used when there is a natural order among the categories.\n",
        "## **Example**: For categories like \"low\", \"medium\", and \"high\", you would assign increasing integers (e.g., 0, 1, 2).\n",
        "## **Advantages**: Preserves the order information.\n",
        "## **Disadvantages**: Only suitable for ordinal categorical variables.\n",
        "## **4. Target Encoding (Mean Encoding)**:\n",
        "\n",
        "## **Principle**: Replaces each category with the mean (or other statistics) of the target variable for that category.\n",
        "## **Example:** If predicting house prices, replace the \"city\" category with the average house price in that city.\n",
        "## **Advantages:** Can capture relationships between the categorical variable and the target variable more effectively.\n",
        "## **Disadvantages:** Can be prone to overfitting, especially with small datasets.\n",
        "\n"
      ],
      "metadata": {
        "id": "tVTK_7ApPXBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7.What do you mean by training and testing a dataset?**"
      ],
      "metadata": {
        "id": "E9dArkK-Q6r6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Training Data:**\n",
        "\n",
        "## This portion of the data is used to \"teach\" the machine learning algorithm. The model learns patterns, relationships, and underlying structures within the training data. It adjusts its internal parameters (weights and biases) to minimize errors and make accurate predictions on the training data.\n",
        "## **2. Testing Data:**\n",
        "\n",
        "## This portion of the data is kept separate from the training data and is used to evaluate how well the trained model performs on unseen data. The model makes predictions on the testing data, and these predictions are compared to the actual known outcomes. This allows you to assess the model's ability to generalize to new, unseen data.\n"
      ],
      "metadata": {
        "id": "wPvU7ANJRSTv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8.What is sklearn.preprocessing?**"
      ],
      "metadata": {
        "id": "6J8JtayuR1cI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sklearn.preprocessing is a submodule within the scikit-learn library in Python that provides a set of tools for data preprocessing."
      ],
      "metadata": {
        "id": "2WUoAzGMSEW3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. What is a Test set?**"
      ],
      "metadata": {
        "id": "D1sKYBmPSRzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In machine learning, a test set is a portion of your data that is completely separate from the data used to train the model."
      ],
      "metadata": {
        "id": "6pDmlO_dSiQu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. How do we split data for model fitting (training and testing) in Python?How do you approach a Machine Learning problem?**"
      ],
      "metadata": {
        "id": "J-YMwL6GSsgb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In machine learning, we split the dataset into training, validation, and test sets to evaluate model performance properly.\n",
        "\n",
        "##  **Common Split Ratios:**\n",
        "## **Training Set (70-80%):** Used to train the model.\n",
        "## **Validation Set (10-15%):** Used to tune hyperparameters and prevent overfitting.\n",
        "## **Test Set (10-20%):** Used to evaluate final model performance on unseen data.\n",
        "\n",
        "## **How to Approach a Machine Learning Problem?**\n",
        "\n",
        "## **Step 1:** Define the Problem\n",
        "\n",
        "## Identify the objective (Regression, Classification, Clustering).\n",
        "## Understand the business or real-world impact.\n",
        "## **Step 2:** Collect & Explore Data\n",
        "\n",
        "##Gather datasets (CSV, databases, APIs).\n",
        "## Check for missing values, outliers, and imbalanced classes.\n",
        "## **Step 3:** Data Preprocessing\n",
        "\n",
        "## Handle missing values (imputation, removal).\n",
        "## Encode categorical variables (One-Hot Encoding, Label Encoding).\n",
        "## Normalize or standardize numerical variables.\n",
        "## Feature engineering (create new features, extract information).\n",
        "## **Step 4:** Split the Data\n",
        "\n",
        "## Divide into training, validation, and test sets.\n",
        "## Use stratified splitting if necessary.\n",
        "## **Step 5:** Choose a Model & Train\n",
        "\n",
        "## Select a model (Linear Regression, Decision Tree, Random Forest, Neural Network).\n",
        "## Train the model using training data.\n",
        "## **Step 6:** Evaluate Model Performance\n",
        "\n",
        "## Use metrics:\n",
        "## Regression → MSE, RMSE, R² Score.\n",
        "## Classification → Accuracy, Precision, Recall, F1-score, ROC-AUC.\n",
        "## **Step 7:** Hyperparameter Tuning\n",
        "\n",
        "## Use Grid Search, Random Search, or Bayesian Optimization to optimize parameters.\n",
        "## **Step 8:** Final Testing & Deployment\n",
        "\n",
        "## Evaluate on test data.\n",
        "## Deploy using Flask, FastAPI, or cloud platforms like AWS/GCP.\n"
      ],
      "metadata": {
        "id": "4BwVFCMSTVdv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11. Why do we have to perform EDA before fitting a model to the data?**"
      ],
      "metadata": {
        "id": "HBU6MEOMhylD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA) is a crucial step before fitting a model to the data because it helps ensure the quality, relevance, and reliability of the data. Here are the key reasons why EDA is important:\n",
        "## **1. Understanding the Data**\n",
        "## EDA helps you grasp the structure, distribution, and patterns within the dataset.\n",
        "## It allows you to check for missing values, outliers, and inconsistencies that might affect model performance.\n",
        "## **2. Detecting Data Quality Issues**\n",
        "## Identifies missing values and suggests ways to handle them (e.g., imputation or removal).\n",
        "## Detects outliers that could distort model predictions.\n",
        "## Uncovers duplicate or erroneous data that needs to be corrected.\n",
        "## **3. Feature Selection & Engineering**\n",
        "## Helps determine which features are relevant and which might be redundant or correlated.\n",
        "## Reveals opportunities for feature transformations, such as scaling, normalization, or encoding categorical variables.\n",
        "## **4. Understanding Relationships Between Variables**\n",
        "## Identifies correlations and dependencies between features.\n",
        "## Helps avoid multicollinearity, which can impact model interpretability and performance.\n",
        "## **5. Choosing the Right Model**\n",
        "## Different data distributions and relationships might favor different models.\n",
        "## Understanding data characteristics helps in selecting between linear, tree-based, or deep learning models.\n",
        "## **6. Preventing Model Bias & Overfitting**\n",
        "## Helps ensure the dataset is representative and does not contain biases that could lead to misleading predictions.\n",
        "## Allows you to split data properly into training, validation, and test sets to ensure generalization.\n",
        "## **7. Improving Model Performance**\n",
        "## Cleaning and preprocessing data through EDA leads to better model accuracy and efficiency.\n",
        "## Helps in selecting appropriate transformations, such as log transformations for skewed distributions."
      ],
      "metadata": {
        "id": "OtdP77XRiXA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **12. What is correlation?**"
      ],
      "metadata": {
        "id": "VGBGSutnjZYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation measures the statistical relationship between two variables. It quantifies how strongly two variables are related and the direction of that relationship."
      ],
      "metadata": {
        "id": "Q9eG4GS9j1yD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **13. What does negative correlation mean?**"
      ],
      "metadata": {
        "id": "3kpqcfaIkBbg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Negative Correlation**: When two variables tend to move in opposite directions.\n",
        "## As one variable increases, the other variable tends to decrease.\n",
        "## **Example**: Temperature and ice cream sales. As the temperature increases, ice cream sales tend to increase."
      ],
      "metadata": {
        "id": "fryBEgxfkSDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **14. How can you find correlation between variables in Python?**"
      ],
      "metadata": {
        "id": "NZPiOE0ikY4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In Python, you can find the correlation between variables using Pandas, NumPy, and Seaborn. Here are different ways to do it:"
      ],
      "metadata": {
        "id": "u9krWRC3k82z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Using corr() in Pandas**\n",
        "## Pandas provides the .corr() method to compute pairwise correlation between columns.\n"
      ],
      "metadata": {
        "id": "bL8nwl2flcz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'A': [1, 2, 3, 4, 5],\n",
        "    'B': [2, 4, 6, 8, 10],\n",
        "    'C': [5, 3, 2, 4, 1]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Compute correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "print(correlation_matrix)\n"
      ],
      "metadata": {
        "id": "g7p9xNSsEEhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7de0325-019f-4b34-c96d-28fa41c5fa2c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     A    B    C\n",
            "A  1.0  1.0 -0.7\n",
            "B  1.0  1.0 -0.7\n",
            "C -0.7 -0.7  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Using Seaborn's Heatmap for Visualization**\n",
        "## A heatmap helps to visualize correlations easily.\n"
      ],
      "metadata": {
        "id": "5bThs5bkmB8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BSsPcPJSmB3Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "INmtTOshDn9E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "4e89c500-cec1-4884-ff32-d742ddb17d32"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAF2CAYAAAB+h6EdAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARGhJREFUeJzt3XlcVNX/P/DXDMuwyS6rJqKGkqafQBGX1ERRUbOsNC2R3FNLsUxKxa2oNLPMPbf66SfTrFT8YAaZkSS44Bbgvjsou2wDMvf3h19HrwwyDDPAhdfz8biPh3Pm3HPf914fvOece+69MkEQBBAREZHkyGs7ACIiItIPkzgREZFEMYkTERFJFJM4ERGRRDGJExERSRSTOBERkUQxiRMREUkUkzgREZFEMYkTERFJFJM4GcWmTZsgk8lw+fJlg7V5+fJlyGQybNq0yWBtSl3Pnj3Rs2fP2g6DiGoJk7iEXLhwARMmTIC3tzcsLCxga2uLrl274quvvkJRUVFth2cwW7duxbJly2o7DJHRo0dDJpPB1tZW67E+d+4cZDIZZDIZlixZUuX2b968iXnz5iE5OdkA0epPJpNhypQpWr978MPsyJEjRtt+XTkORFJhWtsBkG6io6Px6quvQqFQYNSoUWjbti1KSkoQHx+P999/H2fOnMHatWtrO0yD2Lp1K06fPo1p06aJyps1a4aioiKYmZnVSlympqYoLCzE7t278dprr4m+27JlCywsLFBcXKxX2zdv3sT8+fPh5eWFDh066Lzeb7/9ptf26ip9jwNRQ8UkLgGXLl3C8OHD0axZM8TFxcHd3V3z3eTJk3H+/HlER0dXezuCIKC4uBiWlpblvisuLoa5uTnk8tobvJHJZLCwsKi17SsUCnTt2hX//e9/yyXxrVu3IiQkBD/99FONxFJYWAgrKyuYm5vXyPaIqG7icLoEfP7558jPz8f69etFCfyBli1b4t1339V8vnfvHhYuXIgWLVpAoVDAy8sLH374IVQqlWg9Ly8vDBw4EPv27YO/vz8sLS2xZs0aHDhwADKZDD/88ANmz54NT09PWFlZIS8vDwBw+PBh9OvXD3Z2drCyskKPHj3w999/V7ofv/76K0JCQuDh4QGFQoEWLVpg4cKFKCsr09Tp2bMnoqOjceXKFc3wtJeXF4CKr4nHxcWhe/fusLa2hr29PV588UWkpKSI6sybNw8ymQznz5/H6NGjYW9vDzs7O4SFhaGwsLDS2B8YMWIE/ve//yEnJ0dTlpSUhHPnzmHEiBHl6mdlZeG9995Du3btYGNjA1tbW/Tv3x8nTpzQ1Dlw4AA6duwIAAgLC9Ps94P97NmzJ9q2bYujR4/i+eefh5WVFT788EPNd49eEw8NDYWFhUW5/Q8ODoaDgwNu3ryp877qKjU1Fa+88gocHR1hYWEBf39/7Nq1y2jH4eTJk+jRowesrKzQsmVL7NixAwDw559/IiAgAJaWlvDx8cHvv/8uiuHKlSt4++234ePjA0tLSzg5OeHVV18tN2/jwWWDgwcPYsKECXBycoKtrS1GjRqF7OxsAx89ouphT1wCdu/eDW9vb3Tp0kWn+mPHjsXmzZvxyiuvYMaMGTh8+DCioqKQkpKCn3/+WVQ3LS0Nr7/+OiZMmIBx48bBx8dH893ChQthbm6O9957DyqVCubm5oiLi0P//v3h5+eHyMhIyOVybNy4ES+88AL++usvdOrUqcK4Nm3aBBsbG4SHh8PGxgZxcXGYO3cu8vLysHjxYgDARx99hNzcXFy/fh1ffvklAMDGxqbCNn///Xf0798f3t7emDdvHoqKirB8+XJ07doVx44d0/wAeOC1115D8+bNERUVhWPHjuHbb7+Fi4sLPvvsM52O7csvv4yJEydi586deOuttwDc74W3bt0azz33XLn6Fy9exC+//IJXX30VzZs3R3p6OtasWYMePXrg33//hYeHB9q0aYMFCxZg7ty5GD9+PLp37w4AovOdmZmJ/v37Y/jw4XjjjTfg6uqqNb6vvvoKcXFxCA0NRUJCAkxMTLBmzRr89ttv+P777+Hh4VHpPhYXFyMjI6NceX5+frmyM2fOoGvXrvD09MSsWbNgbW2NH3/8EUOGDMFPP/2El156yaDHITs7GwMHDsTw4cPx6quvYtWqVRg+fDi2bNmCadOmYeLEiRgxYgQWL16MV155BdeuXUOjRo0A3P+xdejQIQwfPhxNmjTB5cuXsWrVKvTs2RP//vsvrKysRPs2ZcoU2NvbY968eUhLS8OqVatw5coVzY9cojpBoDotNzdXACC8+OKLOtVPTk4WAAhjx44Vlb/33nsCACEuLk5T1qxZMwGAEBMTI6r7xx9/CAAEb29vobCwUFOuVquFVq1aCcHBwYJardaUFxYWCs2bNxf69OmjKdu4caMAQLh06ZKo3uMmTJggWFlZCcXFxZqykJAQoVmzZuXqXrp0SQAgbNy4UVPWoUMHwcXFRcjMzNSUnThxQpDL5cKoUaM0ZZGRkQIA4a233hK1+dJLLwlOTk7ltvW40NBQwdraWhAEQXjllVeE3r17C4IgCGVlZYKbm5swf/58TXyLFy/WrFdcXCyUlZWV2w+FQiEsWLBAU5aUlFRu3x7o0aOHAEBYvXq11u969OghKtu3b58AQFi0aJFw8eJFwcbGRhgyZEil+ygIggCg0iUpKUlTv3fv3kK7du1E50+tVgtdunQRWrVqZZTjsHXrVk1ZamqqAECQy+XCP//8U+4YPNqOtv9/CQkJAgDhu+++05Q9+L/r5+cnlJSUaMo///xzAYDw66+/VnT4iGoch9PruAdD2A96E5XZu3cvACA8PFxUPmPGDAAod+28efPmCA4O1tpWaGio6Pp4cnKyZtg4MzMTGRkZyMjIQEFBAXr37o2DBw9CrVZXGNujbd29excZGRno3r07CgsLkZqaqtP+PerWrVtITk7G6NGj4ejoqCl/9tln0adPH82xeNTEiRNFn7t3747MzEzNcdbFiBEjcODAASiVSsTFxUGpVGodSgfuX0d/MI+grKwMmZmZsLGxgY+PD44dO6bzNhUKBcLCwnSq27dvX0yYMAELFizAyy+/DAsLC6xZs0bnbb344ovYv39/ueX9998X1cvKykJcXBxee+01zfnMyMhAZmYmgoODce7cOdy4cUMTvyGOg42NDYYPH6757OPjA3t7e7Rp0wYBAQGa8gf/vnjxoqbs0f9/paWlyMzMRMuWLWFvb681hvHjx4smUU6aNAmmpqZa/18R1RYOp9dxtra2AO4nPV1cuXIFcrkcLVu2FJW7ubnB3t4eV65cEZU3b968wrYe/+7cuXMA7if3iuTm5sLBwUHrd2fOnMHs2bMRFxdXLmnm5uZW2GZFHuzLo5cAHmjTpg327duHgoICWFtba8qfeuopUb0HsWZnZ2uOdWUGDBiARo0aYdu2bUhOTkbHjh3RsmVLrffEq9VqfPXVV1i5ciUuXbokuv7v5OSk0/YAwNPTs0qT2JYsWYJff/0VycnJ2Lp1K1xcXHRet0mTJggKCipXfv36ddHn8+fPQxAEzJkzB3PmzNHa1u3bt+Hp6Wmw49CkSZNyQ9l2dnZo2rRpuTIAomvYRUVFiIqKwsaNG3Hjxg0IgqD5Ttv/v1atWok+29jYwN3d3aDPPiCqLibxOs7W1hYeHh44ffp0ldbT9ZqdtpnoFX33oJe9ePHiCm//qej6dU5ODnr06AFbW1ssWLAALVq0gIWFBY4dO4YPPvjgiT14QzIxMdFa/ugf9MooFAq8/PLL2Lx5My5evIh58+ZVWPeTTz7BnDlz8NZbb2HhwoVwdHSEXC7HtGnTqrTPTzpP2hw/fhy3b98GAJw6dQqvv/56ldbXxYP433vvvQpHcx78mDTUcajo/OlyXqdOnYqNGzdi2rRpCAwMhJ2dHWQyGYYPH15j//+IDI1JXAIGDhyItWvXIiEhAYGBgU+s26xZM6jVapw7dw5t2rTRlKenpyMnJwfNmjXTO44WLVoAuP/DQltP7UkOHDiAzMxM7Ny5E88//7ym/NKlS+Xq6voD5MG+pKWllfsuNTUVzs7Ool64IY0YMQIbNmyAXC4XDe8+bseOHejVqxfWr18vKs/JyYGzs7PmsyEnShUUFCAsLAy+vr7o0qULPv/8c7z00kuamd+G4u3tDQAwMzOr9P9DbRwHbTGEhobiiy++0JQVFxeL7jR41Llz59CrVy/N5/z8fNy6dQsDBgwwWoxEVcVr4hIwc+ZMWFtbY+zYsUhPTy/3/YULF/DVV18BgOYPzONPPFu6dCkAICQkRO84/Pz80KJFCyxZskTrTOU7d+5UuO6DntKjPaOSkhKsXLmyXF1ra2udhtfd3d3RoUMHbN68WfSH+PTp0/jtt9+M+se2V69eWLhwIb755hu4ublVWM/ExKRcL3/79u2aa8UPPPixUVFCqYoPPvgAV69exebNm7F06VJ4eXkhNDS03C2G1eXi4oKePXtizZo1uHXrVrnvH/3/UBvH4XHaYli+fLloaP9Ra9euRWlpqebzqlWrcO/ePfTv39/gsRHpiz1xCWjRogW2bt2KYcOGoU2bNqInth06dAjbt2/H6NGjAQDt27dHaGgo1q5dqxnCTkxMxObNmzFkyBBRz6Kq5HI5vv32W/Tv3x/PPPMMwsLC4OnpiRs3buCPP/6Ara0tdu/erXXdLl26wMHBAaGhoXjnnXcgk8nw/fffax3G9vPzw7Zt2xAeHo6OHTvCxsYGgwYN0tru4sWL0b9/fwQGBmLMmDGaW8zs7OyeOMxdXXK5HLNnz6603sCBA7FgwQKEhYWhS5cuOHXqFLZs2aLpxT7QokUL2NvbY/Xq1WjUqBGsra0REBDwxDkL2sTFxWHlypWIjIzU3PK2ceNG9OzZE3PmzMHnn39epfYqs2LFCnTr1g3t2rXDuHHj4O3tjfT0dCQkJOD69eua+8Br+jhoM3DgQHz//fews7ODr68vEhIS8Pvvv1d4Tb6kpAS9e/fGa6+9hrS0NKxcuRLdunXD4MGDqx0LkcHU2rx4qrKzZ88K48aNE7y8vARzc3OhUaNGQteuXYXly5eLbvEpLS0V5s+fLzRv3lwwMzMTmjZtKkRERIjqCML9W8xCQkLKbefBLWbbt2/XGsfx48eFl19+WXBychIUCoXQrFkz4bXXXhNiY2M1dbTdYvb3338LnTt3FiwtLQUPDw9h5syZmluB/vjjD029/Px8YcSIEYK9vb0AQHO7mbZbzARBEH7//Xeha9eugqWlpWBraysMGjRI+Pfff0V1HtxidufOHVG5tji1efQWs4pUdIvZjBkzBHd3d8HS0lLo2rWrkJCQoPXWsF9//VXw9fUVTE1NRfvZo0cP4ZlnntG6zUfbycvLE5o1ayY899xzQmlpqaje9OnTBblcLiQkJDxxHwAIkydP1vrdg2P16C1mgiAIFy5cEEaNGiW4ubkJZmZmgqenpzBw4EBhx44dNXIcKvp//Pi+ZGdnC2FhYYKzs7NgY2MjBAcHC6mpqUKzZs2E0NDQcvv5559/CuPHjxccHBwEGxsbYeTIkaJbGYnqApkgVGFGDxFRPbdp0yaEhYUhKSkJ/v7+tR0O0RPxmjgREZFEMYkTERFJFJM4ERGRRDGJExE9YvTo0RAEgdfDCQcPHsSgQYPg4eEBmUyGX375pdJ1Dhw4gOeeew4KhQItW7Ys99ZFQ2MSJyIi0qKgoADt27fHihUrdKp/6dIlhISEoFevXkhOTsa0adMwduxY7Nu3z2gxcnY6ERFRJWQyGX7++WcMGTKkwjoffPABoqOjRY/JHj58OHJychATE2OUuNgTJyKiBkGlUiEvL0+0GPJJhgkJCeUeQRwcHIyEhASDbeNxdeaJbdFm5d9ERUT1Q1S/tbUdAtWg+N09jNZ2dXJF0kevY/78+aKyyMhIgz3dUalUwtXVVVTm6uqKvLw8FBUVVflFRrqoM0mciIioMjIz/V+SExERgfDwcFGZQqGobki1ikmciIgaBIVCYdSk7ebmVu4lVenp6bC1tTVKLxxgEiciIgmRmxrvdbXVFRgYiL1794rK9u/fX+krpKuDE9uIiEgyZGZyvZeqys/PR3JyMpKTkwHcv4UsOTkZV69eBXB/eH7UqFGa+hMnTsTFixcxc+ZMpKamYuXKlfjxxx8xffp0g+y7NuyJExGRZNRkT/zIkSOi1zc/uJ4eGhqKTZs24datW5qEDgDNmzdHdHQ0pk+fjq+++gpNmjTBt99+i+DgYKPFyCRORESSUZ2JbVXVs2dPPOlRKtqextazZ08cP37ciFGJMYkTEZFk1OVr4rWB18SJiIgkij1xIiKSjJocTpcCJnEiIpIMDqeLMYkTEZFkyEyYxB/FJE5ERJIhZxIX4cQ2IiIiiWJPnIiIJEMmZ0/8UUziREQkGTITDiA/ikmciIgkg9fExZjEiYhIMjicLsYkTkREksGeuBgvLhAREUkUe+JERCQZfNiLGJM4ERFJhkzOAeRHMYkTEZFkcGKbGJM4ERFJBie2iTGJExGRZLAnLsaLC0RERBLFnjgREUkGJ7aJMYkTEZFkcDhdjEmciIgkgxPbxJjEiYhIMtgTF2MSJyIiyeA1cTEeDSIiIoliEiciIsmQyWV6L/pYsWIFvLy8YGFhgYCAACQmJj6x/rJly+Dj4wNLS0s0bdoU06dPR3FxsV7b1gWH04mISDJq8pr4tm3bEB4ejtWrVyMgIADLli1DcHAw0tLS4OLiUq7+1q1bMWvWLGzYsAFdunTB2bNnMXr0aMhkMixdutQoMbInTkREklGTPfGlS5di3LhxCAsLg6+vL1avXg0rKyts2LBBa/1Dhw6ha9euGDFiBLy8vNC3b1+8/vrrlfbeq4NJnIiIJEMml+u9VEVJSQmOHj2KoKAgTZlcLkdQUBASEhK0rtOlSxccPXpUk7QvXryIvXv3YsCAAfrvcCU4nE5ERJJRnfvEVSoVVCqVqEyhUEChUJSrm5GRgbKyMri6uorKXV1dkZqaqrX9ESNGICMjA926dYMgCLh37x4mTpyIDz/8UO+YK8OeOBERNQhRUVGws7MTLVFRUQZr/8CBA/jkk0+wcuVKHDt2DDt37kR0dDQWLlxosG08jj1xIiKSjOpMbIuIiEB4eLioTFsvHACcnZ1hYmKC9PR0UXl6ejrc3Ny0rjNnzhy8+eabGDt2LACgXbt2KCgowPjx4/HRRx9BboR73NkTJyIiyajONXGFQgFbW1vRUlESNzc3h5+fH2JjYzVlarUasbGxCAwM1LpOYWFhuURtYmICABAEwUBHQIw9cSIikoyavMUsPDwcoaGh8Pf3R6dOnbBs2TIUFBQgLCwMADBq1Ch4enpqhuQHDRqEpUuX4j//+Q8CAgJw/vx5zJkzB4MGDdIkc0NjEiciIsmoySQ+bNgw3LlzB3PnzoVSqUSHDh0QExOjmex29epVUc979uzZkMlkmD17Nm7cuIHGjRtj0KBB+Pjjj40Wo0wwVh+/iqLNfGo7BCIykqh+a2s7BKpB8bt7GK3tqxNf1nvdp1bvNGAkdQOviRMREUkUh9OJiEgy+CpSMSZxIiKSDL6KVIxJ3EAcu/nDe8YY2D3XFhYeLjgy9G2k74p98jrPd4Lvklmw8W2F4mu3cD5qFa5/97OoTrNJI+AdPgYKt8bIO5mKM9MWIjfplDF3hXTA891wjRnphUF93dDI2hSnUvKwZOU5XL9VVGH97d8GwN3Volz5zugbWLr6PADA3EyGKWNaoHd3F5iZyZF4PAtfrDqH7JxSo+2HZMnYE3+UQX/SnD592pDNSYqJtRXyTqbh9Dvzdapv6dUEHXetQeaBw4j3fxGXlm9GuzWL4Nynm6aO+6v90WZxBM4tWoH4Ti/h7slUBESvh3ljR2PtBumI57thGjm0KV4Z6IklK89h/HvHUVRchqUL2sHcrOLEMi78GAa/eUizTJt9AgDwR/wdTZ2pY1uiaycnzPnsX0yNSIazowIfRzxj9P2Ropp+FWldV+0kfvfuXaxduxadOnVC+/btDRGTJN3ZdxBnI5ch/dffdarfbPxwFF26jpSZnyE/9SKurNwC5U/70Pzd0Zo6zaeF4dr6H3F9807kp1zAqbcjUVZYjKajhxppL0hXPN8N06uDPfHdj1cQfzgTFy4XYNGXqXByVKB7Z+cK18nJK0VWzsOlS0cnXL9ZhOOncwEA1lYmGNjHDcu/vYBjJ3OQdiEfn3yVimd97fCMT6Oa2jXJqKkXoEiF3nt18OBBhIaGwt3dHUuWLMELL7yAf/75x5Cx1Wv2nTsgI078Jpw7++Ph0LkDAEBmZga7555BRuyhhxUEARlxh2Df+T81GCkZAs+39Hm4WsDZUYGk5GxNWUFhGf49m4e2rW11asPUVIa+vVwR/btSU+bTshHMzOQ4cuJhu1evF0F5uxjP6NguNVxVuiauVCqxadMmrF+/Hnl5eXjttdegUqnwyy+/wNfX11gx1ksKV2eo0jNEZar0DJjZNYLcQgEzBzvITU2hup35WJ1MWPt412SoZAA839Ln6GAOAOWuU2fnlGi+q8zznZ1hY22KvbEPk7iTgzlKStXILygT1c3KKYGTvW7tNiT1dVhcXzon8UGDBuHgwYMICQnBsmXL0K9fP5iYmGD16tVV3qi218GVCmqYyerncAcRSU+fHi54f/LTms8zF1R/gmFIHzccPpqFzKySarfVUNXXYXF96ZzE//e//+Gdd97BpEmT0KpVq2ptNCoqCvPniycEvS5zxEiTiq8r1Teq9AwoXMX7q3B1RmnuXaiLVSjJyIb63j0oXJweq+MElVLco6O6j+dbeuITM/Hv2SOaz+Zm95OHg70ZMrMfJmEHe3Ocv5hfaXuujRXwb++Aj6LOiMozs0tgbiaHjbWJqDfuaG+OzBwm+8exJy6m80+a+Ph43L17F35+fggICMA333yDjAz9/rhEREQgNzdXtLwmb1gzcHP+SYbTC51FZc69uyD7n2QAgFBaitxjZ+D8wiNvy5HJ4NQrEDn/HK/BSMkQeL6lp6ioDDduFWuWS1cLkZGlgn97B00dK0sT+D5ti9OpeZW2FxLkhuzcEiQkiS+ZpJ2/i9JSNfweabeppyXcXCxwRod2GxrOThfTOYl37twZ69atw61btzBhwgT88MMP8PDwgFqtxv79+3H37l2dN6rtdXBSH0o3sbaCbfvWsG3fGgBg1bwJbNu3hkVTdwCAz6JwtN/4mab+lbU/wKp5U7SOeh/WPt5oNnEE3F/tj0tfbdLUubRsI5qOeQ2ebw6BTWtvtF0xD6bWlri2uf49/1dqeL4bpu27biB02FPo2skJ3s2sMTu8NTKzVPjrn4cdmmWLnsXLIR6i9WQyYECQG2Li0lGmFrdZUFiGPfuVmDqmBf7Tzh4+LWzw4bs+OJWSizNpuv9dbTDkcv2XeqjKD3uxtrbGW2+9hbfeegtpaWlYv349Pv30U8yaNQt9+vTBrl27jBFnnWfn1xaBsd9rPvsu+RAAcO27nTg5JgIK98aw/L8/8ABQdPk6kgZPgO8XEfCaOgrF15U4NWE2MvbHa+rc2v4/mDd2xNOR79x/+MeJFCQOHIuSxyY/Uc3j+W6Ytvx0DRYWJpg55WnYWJvi1L+5mBF5CiWlD98j5elmCXtbM9F6/h0c4OZigej9ysebBAAs//Y8BKEFPo7wvf+wl2P3H/ZCVBmDvMWsrKwMu3fvxoYNG/RO4nyLGVH9xbeYNSzGfIvZndlheq/beNFGA0ZSNxjksasmJiYYMmQIhgwZYojmiIiItOLsdDE+O52IiCSjvk5Q0xeTOBERSQd74iJM4kREJBnsiYvxJw0REZFEsSdORESSIZP4M0UMjUmciIikg8PpIkziREQkGbzFTIxJnIiIJIMT28SYxImISDp4TVyER4OIiEiimMSJiEgyavpVpCtWrICXlxcsLCwQEBCAxMTEJ9bPycnB5MmT4e7uDoVCgaeffhp79+7Va9u64HA6ERFJRw1ObNu2bRvCw8OxevVqBAQEYNmyZQgODkZaWhpcXFzK1S8pKUGfPn3g4uKCHTt2wNPTE1euXIG9vb3RYmQSJyIiyZDJam5i29KlSzFu3DiEhd1/c9rq1asRHR2NDRs2YNasWeXqb9iwAVlZWTh06BDMzO6/jtbLy8uoMXI4nYiIpEMu13+pgpKSEhw9ehRBQUGPbFqOoKAgJCQkaF1n165dCAwMxOTJk+Hq6oq2bdvik08+QVlZWbV2+UnYEyciIsmozi1mKpUKKpVKVKZQKKBQKMrVzcjIQFlZGVxdXUXlrq6uSE1N1dr+xYsXERcXh5EjR2Lv3r04f/483n77bZSWliIyMlLvuJ+EPXEiImoQoqKiYGdnJ1qioqIM1r5arYaLiwvWrl0LPz8/DBs2DB999BFWr15tsG08jj1xIiKSjmrcJx4REYHw8HBRmbZeOAA4OzvDxMQE6enpovL09HS4ublpXcfd3R1mZmYwMTHRlLVp0wZKpRIlJSUwNzfXO/aKsCdORETSIZfpvSgUCtja2oqWipK4ubk5/Pz8EBsbqylTq9WIjY1FYGCg1nW6du2K8+fPQ61Wa8rOnj0Ld3d3oyRwgEmciIgkRCaT671UVXh4ONatW4fNmzcjJSUFkyZNQkFBgWa2+qhRoxAREaGpP2nSJGRlZeHdd9/F2bNnER0djU8++QSTJ0822P4/jsPpREQkHTX47PRhw4bhzp07mDt3LpRKJTp06ICYmBjNZLerV69C/sis96ZNm2Lfvn2YPn06nn32WXh6euLdd9/FBx98YLQYZYIgCEZrvQqizXxqOwQiMpKofmtrOwSqQfG7exit7cL1c/Ve12rMAgNGUjdwOJ2IiEiiOJxORETSUYNPbJMCJnEiIpKOGnx2uhQwiRMRkXSwJy7CJE5ERJIhY09chEmciIikoxpPbKuPeDSIiIgkij1xIiKSjhp82IsUMIkTEZFk6PP41PqMSZyIiKSDPXERJnEiIpIO9sRFeDSIiIgkij1xIiKSDj7sRYRJnIiIpIMPexFhEiciIungNXERJnEiIpIOzk4XYRInIiLpYE9chEeDiIhIotgTJyIi6eDsdBEmcSIikg7OThdhEiciIulgT1yESZyIiKSDE9tEmMSJiEg6OJwuwqNBREQkUeyJExGRdPCauAiTOBERSQeviYvwaBARkXTIZPovelixYgW8vLxgYWGBgIAAJCYm6rTeDz/8AJlMhiFDhui1XV0xiRMRkXTI5fovVbRt2zaEh4cjMjISx44dQ/v27REcHIzbt28/cb3Lly/jvffeQ/fu3fXdS50xiRMRkWQIMpneS1UtXboU48aNQ1hYGHx9fbF69WpYWVlhw4YNFa5TVlaGkSNHYv78+fD29q7OruqESZyIiBoElUqFvLw80aJSqbTWLSkpwdGjRxEUFKQpk8vlCAoKQkJCQoXbWLBgAVxcXDBmzBiDx68NkzgREUmHTK73EhUVBTs7O9ESFRWldTMZGRkoKyuDq6urqNzV1RVKpVLrOvHx8Vi/fj3WrVtn8N2uCGenExGRdFRjdnpERATCw8NFZQqForoRAQDu3r2LN998E+vWrYOzs7NB2tQFkzgREUmGPte2H1AoFDonbWdnZ5iYmCA9PV1Unp6eDjc3t3L1L1y4gMuXL2PQoEGaMrVaDQAwNTVFWloaWrRooXfsFeFwOhERSUc1htOrwtzcHH5+foiNjdWUqdVqxMbGIjAwsFz91q1b49SpU0hOTtYsgwcPRq9evZCcnIymTZtWe9e1YU+ciIikowaf2BYeHo7Q0FD4+/ujU6dOWLZsGQoKChAWFgYAGDVqFDw9PREVFQULCwu0bdtWtL69vT0AlCs3JCZxIiIiLYYNG4Y7d+5g7ty5UCqV6NChA2JiYjST3a5evQp5Lb+QRSYIglCrEfyfaDOf2g6BiIwkqt/a2g6BalD87h5Ga7vw75/0Xteq61ADRlI3sCdORESSUZ2JbfURkzgREUkHX4AiwiRORESSITCJizCJExGRdHA4XYQ/aYiIiCSKPXEiIpIMDqeLMYkTEZF0cDhdhEmciIikgz1xESZxIiKSDN4nLsYkTkRE0sGeuAiPBhERkUSxJ05ERJIhgMPpj2ISJyIiyeAtZmJM4kREJB1M4iJM4kREJBmcnS7GJE5ERJLB4XQxHg0iIiKJYk+ciIikg8PpIkziREQkGRxOF2MSJyIiyeB94mJM4kREJBnsiYsxiRMRkXTwmrgIf9IQERFJFHviREQkGQL7niJM4kREJBl8YpsYf9IQEZFkCDK53os+VqxYAS8vL1hYWCAgIACJiYkV1l23bh26d+8OBwcHODg4ICgo6In1DYFJnIiIJEOATO+lqrZt24bw8HBERkbi2LFjaN++PYKDg3H79m2t9Q8cOIDXX38df/zxBxISEtC0aVP07dsXN27cqO5uV0gmCIJgtNarINrMp7ZDICIjieq3trZDoBoUv7uH0dq+mXZS73U9fJ6tUv2AgAB07NgR33zzDQBArVajadOmmDp1KmbNmlXp+mVlZXBwcMA333yDUaNG6RVzZdgTJyKiBkGlUiEvL0+0qFQqrXVLSkpw9OhRBAUFacrkcjmCgoKQkJCg0/YKCwtRWloKR0dHg8SvDZM4ERFJhiCT6b1ERUXBzs5OtERFRWndTkZGBsrKyuDq6ioqd3V1hVKp1CnWDz74AB4eHqIfAobG2elERCQZ1XnsakREBMLDw0VlCoWiuiFp9emnn+KHH37AgQMHYGFhYZRtAEziREQkIdV57KpCodA5aTs7O8PExATp6emi8vT0dLi5uT1x3SVLluDTTz/F77//jmefrdp1+KricLqBOHbzh//Pq9D7yl8IKU2D6+Dela/zfCd0S9yJfvmn0DPlNzQZ9VK5Os0mjUCvc7Hod/ckuvz9I+w6tjNG+FRFPN8N15iRXvhlc2fE7uiGZQufRRN3yyfW3/5tAOJ39yi3hE9sqaljbiZD+MSWiN7SBb/92A2LInzhYG9m7F2RpJqanW5ubg4/Pz/ExsZqytRqNWJjYxEYGFjhep9//jkWLlyImJgY+Pv7672fumISNxATayvknUzD6Xfm61Tf0qsJOu5ag8wDhxHv/yIuLd+MdmsWwblPN00d91f7o83iCJxbtALxnV7C3ZOpCIheD/PGxpskQbrh+W6YRg5tilcGemLJynMY/95xFBWXYemCdjA3qzhBjAs/hsFvHtIs02afAAD8EX9HU2fq2Jbo2skJcz77F1MjkuHsqMDHEc8YfX+kqCbvEw8PD8e6deuwefNmpKSkYNKkSSgoKEBYWBgAYNSoUYiIiNDU/+yzzzBnzhxs2LABXl5eUCqVUCqVyM/PN9j+P47D6QZyZ99B3Nl3UOf6zcYPR9Gl60iZ+RkAID/1Ihy7+KH5u6ORsT8eANB8Whiurf8R1zfvBACcejsSLv17ounoobiweJ3hd4J0xvPdML062BPf/XgF8YczAQCLvkzFru+7oHtnZ8T+dUfrOjl5paLPb7zihOs3i3D8dC4AwNrKBAP7uGH+khQcO5kDAPjkq1RsXdUJz/g0wpm0u8bbIXqiYcOG4c6dO5g7dy6USiU6dOiAmJgYzWS3q1evQi5/+ONg1apVKCkpwSuvvCJqJzIyEvPmzTNKjEzitcS+cwdkxIlvU7izPx6+X3wIAJCZmcHuuWdw4bM1DysIAjLiDsG+839qMlQyAJ5v6fNwtYCzowJJydmasoLCMvx7Ng9tW9tWmMQfZWoqQ99ertj2y3VNmU/LRjAzk+PIiYftXr1eBOXtYjzT2pZJ/DE1/T7xKVOmYMqUKVq/O3DggOjz5cuXjR/QY/RK4pmZmXBycgIAXLt2DevWrUNRUREGDx6M7t27GzTA+krh6gxVeoaoTJWeATO7RpBbKGDmYAe5qSlUtzMfq5MJax/vmgyVDIDnW/ocHcwBANk54p51dk6J5rvKPN/ZGTbWptgb+/AWJScHc5SUqpFfUCaqm5VTAid73dptSPg+cbEqJfFTp05h0KBBuHbtGlq1aoUffvgB/fr1Q0FBAeRyOb788kvs2LEDQ4YMeWI7KpWq3A32pYIaZjw5RFRH9OnhgvcnP635PHPBqWq3GdLHDYePZiEzq6TabTVUNd0Tr+uqlDVnzpyJdu3a4eDBg+jZsycGDhyIkJAQ5ObmIjs7GxMmTMCnn35aaTvabrj/UZ2l905IkSo9AwpXZ1GZwtUZpbl3oS5WoSQjG+p796BwcXqsjhNUSnGPjuo+nm/piU/MRNi7RzRL7v9d23581riDvTmysitPyq6NFfBv74Ddv90SlWdml8DcTA4baxNRuaO9OTJzmOwfV52HvdRHVUriSUlJ+Pjjj9G1a1csWbIEN2/exNtvvw25XA65XI6pU6ciNTW10nYiIiKQm5srWl6TN6wZuDn/JMPphc6iMufeXZD9TzIAQCgtRe6xM3B+4ZFbGWQyOPUKRM4/x2swUjIEnm/pKSoqw41bxZrl0tVCZGSp4N/eQVPHytIEvk/b4nRqXqXthQS5ITu3BAlJ4ksmaefvorRUDb9H2m3qaQk3Fwuc0aHdhkYQZHov9VGVhtOzsrI0N7nb2NjA2toaDg4P/+M5ODjg7t3KJ2Fou+Fe6kPpJtZWsG75lOazVfMmsG3fGiVZuSi+dgs+i8Jh4emKE2EfAACurP0Bzd4eidZR7+Papp/g3Ksz3F/tj6TBEzRtXFq2Ee03fIaco6eRm3QSXu+EwtTaEtf+b/Yy1R6e74Zp+64bCB32FK7dLMKt9GKMfcMLmVkq/PXPw9GSZYuexcGEDOyMvqkpk8mAAUFuiIlLR5la3GZBYRn27Fdi6pgWyLt7D4WF9zBtQkucSsnlpDaqVJUntskeG5J4/HNDZefXFoGx32s++y65P+v42nc7cXJMBBTujWHZ1F3zfdHl60gaPAG+X0TAa+ooFF9X4tSE2ZrbjQDg1vb/wbyxI56OfAcKt8bIO5GCxIFjUfLY5CeqeTzfDdOWn67BwsIEM6c8DRtrU5z6NxczIk+hpPThyyA93Sxhbysecvfv4AA3FwtE79f+zO3l356HILTAxxG+MDOTI/FYFr5Ydc6o+yJVAh9vIlKlV5HK5XL0799f04vevXs3XnjhBVhbWwO4P2EtJiYGZWVlT2pGK76KlKj+4qtIGxZjvor07IWreq/7dIunKq8kMVXqiYeGhoo+v/HGG+XqGOudqURERJydLlalJL5x40ZjxUFERFQpJnExPrGNiIgkg0lcjDMEiIiIJIo9cSIikoz6er+3vpjEiYhIMjicLsYkTkREksEkLsYkTkREksEkLsaJbURERBLFnjgREUkGJ7aJMYkTEZFkqDmcLsIkTkREksFr4mJM4kREJBkcThdjEiciIslgT1yMs9OJiIgkij1xIiKSDA6nizGJExGRZHA4XYxJnIiIJIM9cTFeEyciIslQV2PRx4oVK+Dl5QULCwsEBAQgMTHxifW3b9+O1q1bw8LCAu3atcPevXv13LJumMSJiEgyBEGm91JV27ZtQ3h4OCIjI3Hs2DG0b98ewcHBuH37ttb6hw4dwuuvv44xY8bg+PHjGDJkCIYMGYLTp09Xd7crJBMEQTBa61UQbeZT2yEQkZFE9Vtb2yFQDYrf3cNobSek5Om9bmAb2yrVDwgIQMeOHfHNN98AANRqNZo2bYqpU6di1qxZ5eoPGzYMBQUF2LNnj6asc+fO6NChA1avXq133E/CnjgREUmGAJnei0qlQl5enmhRqVRat1NSUoKjR48iKChIUyaXyxEUFISEhASt6yQkJIjqA0BwcHCF9Q2BSZyIiCSjOsPpUVFRsLOzEy1RUVFat5ORkYGysjK4urqKyl1dXaFUKrWuo1Qqq1TfEDg7nYiIJKM6t5hFREQgPDxcVKZQKKobUq1iEiciIslQV2MWl0Kh0DlpOzs7w8TEBOnp6aLy9PR0uLm5aV3Hzc2tSvUNgcPpREQkGdW5Jl4V5ubm8PPzQ2xsrKZMrVYjNjYWgYGBWtcJDAwU1QeA/fv3V1jfENgTJyIi0iI8PByhoaHw9/dHp06dsGzZMhQUFCAsLAwAMGrUKHh6emquq7/77rvo0aMHvvjiC4SEhOCHH37AkSNHsHat8e7OYBInIiLJqMkntg0bNgx37tzB3LlzoVQq0aFDB8TExGgmr129ehVy+cMB7S5dumDr1q2YPXs2PvzwQ7Rq1Qq//PIL2rZta7QYeZ84ERkd7xNvWIx5n/gfp4r0XrdXO0sDRlI3sCdORESSoeYLUESYxImISDL4AhQxJnEiIpKMunEBuO7gLWZEREQSxZ44ERFJRnWe2FYfMYkTEZFkVOeJbfURkzgREUkGJ7aJMYkTEZFkcGKbGJM4ERFJBu8TF+PsdCIiIoliT5yIiCSDw+liTOJERCQZnNgmxiRORESSwVvMxJjEiYhIMjicLsYkTkREksEntolxdjoREZFEsSdORESSwWviYkziREQkGbwmLlZnknhUv7W1HQIRGUlEzPjaDoFqVJrRWmYSF6szSZyIiKgyat4nLsIkTkREksGeuBhnpxMREUkUe+JERCQZ7ImLMYkTEZFk8BYzMSZxIiKSDL4ARYzXxImISDIEQf/FmLKysjBy5EjY2trC3t4eY8aMQX5+/hPrT506FT4+PrC0tMRTTz2Fd955B7m5uVXaLnviREQkGXV1OH3kyJG4desW9u/fj9LSUoSFhWH8+PHYunWr1vo3b97EzZs3sWTJEvj6+uLKlSuYOHEibt68iR07dui8XZkg1I1pAt0G/VnbIRCRkfBhLw1LSKnxHvay6YD+647uaagoxFJSUuDr64ukpCT4+/sDAGJiYjBgwABcv34dHh4eOrWzfft2vPHGGygoKICpqW59bA6nExGRZNTF4fSEhATY29trEjgABAUFQS6X4/Dhwzq3k5ubC1tbW50TOMDhdCIikpDqJGOVSgWVSiUqUygUUCgU1YpJqVTCxcVFVGZqagpHR0colUqd2sjIyMDChQsxfnzVRq3YEyciIslQC/ovUVFRsLOzEy1RUVEVbmvWrFmQyWRPXFJTU6u9T3l5eQgJCYGvry/mzZtXpXXZEyciIsmoTk88IiIC4eHhorIn9cJnzJiB0aNHP7FNb29vuLm54fbt26Lye/fuISsrC25ubk9c/+7du+jXrx8aNWqEn3/+GWZmZk/eiccwiRMRkWSo1fqvW9Wh88aNG6Nx48aV1gsMDEROTg6OHj0KPz8/AEBcXBzUajUCAgIqXC8vLw/BwcFQKBTYtWsXLCwsdI7tAQ6nExERVUObNm3Qr18/jBs3DomJifj7778xZcoUDB8+XDMz/caNG2jdujUSExMB3E/gffv2RUFBAdavX4+8vDwolUoolUqUlZXpvG32xImISDLqxk3R5W3ZsgVTpkxB7969IZfLMXToUHz99dea70tLS5GWlobCwkIAwLFjxzQz11u2bClq69KlS/Dy8tJpu0ziREQkGXU1iTs6Olb4YBcA8PLywqOPZenZsycM8ZgWJnEiIpKMuvrEttrCJE5ERJJRvd5r/Xt5CpM4ERFJRl0dTq8tnJ1OREQkUeyJExGRZFTnPvH6iEmciIgkg8PpYkziREQkGZydLsYkTkREksGeuBiTOBERSYZQra54/bvFjLPTiYiIJIo9cSIikgxeExdjEiciIsngNXExJnEiIpIMNbviIkziREQkGeyJizGJExGRZDCJi3F2OhERkUSxJ05ERJKhZldchEmciIgkQ+ALUESYxImISDIE9sRFmMSJiEgy+CpSMU5sIyIikij2xImISDI4nC7GJE5ERJLBB7aJMYkTEZFkVO9VpPUPkzgREUkGR9PFOLGNiIgkQ60W9F6MKSsrCyNHjoStrS3s7e0xZswY5Ofn67SuIAjo378/ZDIZfvnllyptl0mciIiomkaOHIkzZ85g//792LNnDw4ePIjx48frtO6yZcsgk8n02i6H041gzEgvDOrrhkbWpjiVkoclK8/h+q2iCutv/zYA7q4W5cp3Rt/A0tXnAQDmZjJMGdMCvbu7wMxMjsTjWfhi1Tlk55QabT9INzzf9Z9jN394zxgDu+fawsLDBUeGvo30XbFPXuf5TvBdMgs2vq1QfO0WzketwvXvfhbVaTZpBLzDx0Dh1hh5J1NxZtpC5CadMuauSF5dnJ2ekpKCmJgYJCUlwd/fHwCwfPlyDBgwAEuWLIGHh0eF6yYnJ+OLL77AkSNH4O7uXuVtsyduYCOHNsUrAz2xZOU5jH/vOIqKy7B0QTuYm1X8K2tc+DEMfvOQZpk2+wQA4I/4O5o6U8e2RNdOTpjz2b+YGpEMZ0cFPo54xuj7Q0/G890wmFhbIe9kGk6/M1+n+pZeTdBx1xpkHjiMeP8XcWn5ZrRbswjOfbpp6ri/2h9tFkfg3KIViO/0Eu6eTEVA9HqYN3Y01m7UC4Ja/8VYEhISYG9vr0ngABAUFAS5XI7Dhw9XuF5hYSFGjBiBFStWwM3NTa9tM4kb2KuDPfHdj1cQfzgTFy4XYNGXqXByVKB7Z+cK18nJK0VWzsOlS0cnXL9ZhOOncwEA1lYmGNjHDcu/vYBjJ3OQdiEfn3yVimd97fCMT6Oa2jXSgue7Ybiz7yDORi5D+q+/61S/2fjhKLp0HSkzP0N+6kVcWbkFyp/2ofm7ozV1mk8Lw7X1P+L65p3IT7mAU29HoqywGE1HDzXSXtQPakHQe1GpVMjLyxMtKpWq2jEplUq4uLiIykxNTeHo6AilUlnhetOnT0eXLl3w4osv6r3tKiXxuLg4+Pr6Ii8vr9x3ubm5eOaZZ/DXX3/pHYzUebhawNlRgaTkbE1ZQWEZ/j2bh7atbXVqw9RUhr69XBH9+8MT79OyEczM5Dhy4mG7V68XQXm7GM/o2C4ZHs83VcS+cwdkxCWIyu7sj4dD5w4AAJmZGeyeewYZsYceVhAEZMQdgn3n/9RgpNIjCILeS1RUFOzs7ERLVFRUhduaNWsWZDLZE5fU1FS99mPXrl2Ii4vDsmXL9DwS91XpmviyZcswbtw42NqW/0NiZ2eHCRMmYOnSpejevXu1gpIqRwdzACh33TI7p0TzXWWe7+wMG2tT7I19+EfdycEcJaVq5BeUiepm5ZTAyV63dsnweL6pIgpXZ6jSM0RlqvQMmNk1gtxCATMHO8hNTaG6nflYnUxY+3jXZKiSU51Z5hEREQgPDxeVKRSKCuvPmDEDo0ePfmKb3t7ecHNzw+3bt0Xl9+7dQ1ZWVoXD5HFxcbhw4QLs7e1F5UOHDkX37t1x4MCBJ273gSol8RMnTuCzzz6r8Pu+fftiyZIllbajUqnKDWGoy0ogN5HWH6g+PVzw/uSnNZ9nLqj+hJSQPm44fDQLmVkl1W6LDIvnm0jaFArFE5P24xo3bozGjRtXWi8wMBA5OTk4evQo/Pz8ANxP0mq1GgEBAVrXmTVrFsaOHSsqa9euHb788ksMGjRI5xirlMTT09NhZmZWcWOmprhz506F3z8QFRWF+fPFE0SatgrFUz5hVQmn1sUnZuLfs0c0n83N7l+dcLA3Q2b2wz/KDvbmOH+x8vsFXRsr4N/eAR9FnRGVZ2aXwNxMDhtrE1HvzNHeHJk5/ONfU3i+SVeq9AwoXMXzIhSuzijNvQt1sQolGdlQ37sHhYvTY3WcoFKKe/AkVgcnp6NNmzbo168fxo0bh9WrV6O0tBRTpkzB8OHDNTPTb9y4gd69e+O7775Dp06d4ObmprWX/tRTT6F58+Y6b7tK18Q9PT1x+vTpCr8/efKkTlPkIyIikJubK1qatBxZlVDqhKKiMty4VaxZLl0tREaWCv7tHTR1rCxN4Pu0LU6nlp9H8LiQIDdk55YgIUk8xJZ2/i5KS9Xwe6Tdpp6WcHOxwBkd2iXD4PkmXeX8kwynFzqLypx7d0H2P8kAAKG0FLnHzsD5hcCHFWQyOPUKRM4/x2swUukR1ILeizFt2bIFrVu3Ru/evTFgwAB069YNa9eu1XxfWlqKtLQ0FBYWGnS7VeqJDxgwAHPmzEG/fv1gYSG+z7WoqAiRkZEYOHBgpe1oG9KQ2lB6RbbvuoHQYU/h2s0i3Eovxtg3vJCZpcJf/zz8db1s0bM4mJCBndE3NWUyGTAgyA0xcekoe+xWiILCMuzZr8TUMS2Qd/ceCgvvYdqEljiVkoszaXdratdIC57vhsHE2grWLZ/SfLZq3gS27VujJCsXxdduwWdROCw8XXEi7AMAwJW1P6DZ2yPROup9XNv0E5x7dYb7q/2RNHiCpo1Lyzai/YbPkHP0NHKTTsLrnVCYWlvi2uadNb5/UqKui11xAI6Ojti6dWuF33t5eVV6j7s+98BXKYnPnj0bO3fuxNNPP40pU6bAx8cHAJCamooVK1agrKwMH330UZWDqE+2/HQNFhYmmDnladhYm+LUv7mYEXkKJaUPT46nmyXsbcWXJfw7OMDNxQLR+7XfjrD82/MQhBb4OML3/sM/jt1/+AfVLp7vhsHOry0CY7/XfPZd8iEA4Np3O3FyTAQU7o1h2fThKGTR5etIGjwBvl9EwGvqKBRfV+LUhNnI2B+vqXNr+/9g3tgRT0e+c/9hLydSkDhwLEoem+xGYnwBiphMqGLqv3LlCiZNmoR9+/ZpfjXIZDIEBwdjxYoVVRrLf1S3QX/qtR4R1X0RMbo9fpLqh5DSNKO1PXlJjt7rrnjP3mBx1BVVfuxqs2bNsHfvXmRnZ+P8+fMQBAGtWrWCg4ND5SsTERGRwej97HQHBwd07NjRkLEQERE9EUfTxfgCFCIikgxeExdjEiciIsmoi28xq01M4kREJBnVeexqfcQkTkREksGeuBhfRUpERCRR7IkTEZFkcGKbGJM4ERFJBpO4GJM4ERFJRl19dnptYRInIiLJYE9cjEmciIgkg7PTxTg7nYiISKLYEyciIsngw17EmMSJiEgyeE1cjEmciIgkg9fExZjEiYhIMgS1urZDqFOYxImISDJ4TVyMs9OJiIgkij1xIiKSDF4TF2MSJyIiyeDsdDEmcSIikgwmcTEmcSIikgy1wNnpj2ISJyIiyWBPXIyz04mIiKopKysLI0eOhK2tLezt7TFmzBjk5+dXul5CQgJeeOEFWFtbw9bWFs8//zyKiop03i6TOBERSYagFvRejGnkyJE4c+YM9u/fjz179uDgwYMYP378E9dJSEhAv3790LdvXyQmJiIpKQlTpkyBXK57auZwOhERSUZdvMUsJSUFMTExSEpKgr+/PwBg+fLlGDBgAJYsWQIPDw+t602fPh3vvPMOZs2apSnz8fGp0rbZEyciIslQq9V6LyqVCnl5eaJFpVJVO6aEhATY29trEjgABAUFQS6X4/Dhw1rXuX37Ng4fPgwXFxd06dIFrq6u6NGjB+Lj46u0bSZxIiKSjOoMp0dFRcHOzk60REVFVTsmpVIJFxcXUZmpqSkcHR2hVCq1rnPx4kUAwLx58zBu3DjExMTgueeeQ+/evXHu3Dmdt80kTkREkiEIar2XiIgI5ObmipaIiIgKtzVr1izIZLInLqmpqXrth/r/XuQyYcIEhIWF4T//+Q++/PJL+Pj4YMOGDTq3w2viRETUICgUCigUCp3rz5gxA6NHj35iHW9vb7i5ueH27dui8nv37iErKwtubm5a13N3dwcA+Pr6isrbtGmDq1ev6hwjkzgREUlGTd4n3rhxYzRu3LjSeoGBgcjJycHRo0fh5+cHAIiLi4NarUZAQIDWdby8vODh4YG0tDRR+dmzZ9G/f3+dY+RwOhERSUZdvMWsTZs26NevH8aNG4fExET8/fffmDJlCoYPH66ZmX7jxg20bt0aiYmJAACZTIb3338fX3/9NXbs2IHz589jzpw5SE1NxZgxY3TeNnviREQkGXX1satbtmzBlClT0Lt3b8jlcgwdOhRff/215vvS0lKkpaWhsLBQUzZt2jQUFxdj+vTpyMrKQvv27bF//360aNFC5+3KhDpy0123QX/WdghEZCQRMU9+6AXVLyGlaZVX0lPfN4/rve5v3//HgJHUDeyJExGRZAjqutkTry28Jk5ERCRR7IkTEZFk8C1mYkziREQkGUIdndhWW5jEiYhIMtTsiYswiRMRkWRwYpsYkzgREUkGr4mLcXY6ERGRRLEnTkREksGJbWJM4kREJBkcThdjEiciIsngxDaxOvPs9IZIpVIhKioKERERVXrHLUkTz3fDwvNNNYFJvBbl5eXBzs4Oubm5sLW1re1wyMh4vhsWnm+qCZydTkREJFFM4kRERBLFJE5ERCRRTOK1SKFQIDIykpNeGgie74aF55tqAie2ERERSRR74kRERBLFJE5ERCRRTOJEREQSxSROREQkUUzitSQhIQEmJiYICQmp7VDIiEaPHg2ZTKZZnJyc0K9fP5w8ebK2QyMjUiqVmDp1Kry9vaFQKNC0aVMMGjQIsbGxtR0a1TNM4rVk/fr1mDp1Kg4ePIibN2/WdjhkRP369cOtW7dw69YtxMbGwtTUFAMHDqztsMhILl++DD8/P8TFxWHx4sU4deoUYmJi0KtXL0yePLm2w6N6hreY1YL8/Hy4u7vjyJEjiIyMxLPPPosPP/ywtsMiIxg9ejRycnLwyy+/aMri4+PRvXt33L59G40bN6694MgoBgwYgJMnTyItLQ3W1tai73JycmBvb187gVG9xJ54Lfjxxx/RunVr+Pj44I033sCGDRvA31INQ35+Pv7f//t/aNmyJZycnGo7HDKwrKwsxMTEYPLkyeUSOAAmcDI4vk+8Fqxfvx5vvPEGgPtDrbm5ufjzzz/Rs2fP2g2MjGLPnj2wsbEBABQUFMDd3R179uyBXM7f0PXN+fPnIQgCWrduXduhUAPBvyI1LC0tDYmJiXj99dcBAKamphg2bBjWr19fy5GRsfTq1QvJyclITk5GYmIigoOD0b9/f1y5cqW2QyMD44ga1TT2xGvY+vXrce/ePXh4eGjKBEGAQqHAN998Azs7u1qMjozB2toaLVu21Hz+9ttvYWdnh3Xr1mHRokW1GBkZWqtWrSCTyZCamlrboVADwZ54Dbp37x6+++47fPHFF5qeWXJyMk6cOAEPDw/897//re0QqQbIZDLI5XIUFRXVdihkYI6OjggODsaKFStQUFBQ7vucnJyaD4rqNSbxGrRnzx5kZ2djzJgxaNu2rWgZOnQoh9TrKZVKBaVSCaVSiZSUFEydOhX5+fkYNGhQbYdGRrBixQqUlZWhU6dO+Omnn3Du3DmkpKTg66+/RmBgYG2HR/UMk3gNWr9+PYKCgrQOmQ8dOhRHjhzhQ0DqoZiYGLi7u8Pd3R0BAQFISkrC9u3bOZGxnvL29saxY8fQq1cvzJgxA23btkWfPn0QGxuLVatW1XZ4VM/wPnEiIiKJYk+ciIhIopjEiYiIJIpJnIiISKKYxImIiCSKSZyIiEiimMSJiIgkikmciIhIopjEiYiIJIpJnIiISKKYxImIiCSKSZyIiEiimMSJiIgk6v8Dl1kL8aSgosIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix Heatmap\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Using NumPy’s corrcoef()**\n",
        "## If you have two NumPy arrays instead of a DataFrame:"
      ],
      "metadata": {
        "id": "FlT0TCFqmTYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([1, 2, 3, 4, 5])\n",
        "B = np.array([2, 4, 6, 8, 10])\n",
        "\n",
        "correlation = np.corrcoef(A, B)\n",
        "print(correlation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-An0ub3nmMNC",
        "outputId": "fcf5e9b0-b2bd-4c6e-8145-b8b01b11fb53"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1.]\n",
            " [1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **15. What is causation? Explain difference between correlation and causation with an example.**"
      ],
      "metadata": {
        "id": "U6hwvhIomlIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Causation** means that a change in one variable directly causes a change in another. In other words, there is a cause-and-effect relationship between two variables.\n",
        "\n",
        "## **Difference Between Correlation and Causation**\n",
        "## **Correlation**\n",
        "## -> Measures the relationship between two variables.\n",
        "## -> Does not indicate which variable influences the other.\n",
        "## -> There may be a third variable (confounder) influencing both.\n",
        "## -> Statistical methods (e.g., Pearson correlation).\n",
        "\n",
        "## **Causation**\n",
        "\n",
        "## -> One variable directly affects another.\n",
        "## -> Shows cause-and-effect direction.\n",
        "## -> The effect is directly due to the independent variable.\n",
        "## -> Requires experiments or controlled studies.\n",
        "\n"
      ],
      "metadata": {
        "id": "66jaG7G7m2p4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **16. What is an Optimizer? What are different types of optimizers? Explain each with an example.**"
      ],
      "metadata": {
        "id": "cF9hTwiCrZ2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## An optimizer in machine learning and deep learning is an algorithm that adjusts model parameters (weights & biases) to minimize the loss function and improve accuracy. It updates the parameters iteratively to find the optimal values that best fit the data.\n",
        "\n",
        "## **1. First-Order Optimization Algorithms (Gradient-Based)**\n",
        "## These optimizers use gradients of the loss function to update model parameters.\n",
        "\n",
        "## **(a) Gradient Descent (GD)**\n",
        "## The most basic optimization algorithm.\n",
        "## Updates parameters using the gradient of the loss function.\n",
        "## Formula:\n",
        "\n",
        "𝜃\n",
        "=\n",
        "𝜃\n",
        "−\n",
        "𝛼\n",
        "∇\n",
        "𝐽\n",
        "(\n",
        "𝜃\n",
        ")\n",
        "\n",
        "\n",
        "## Types of Gradient Descent:\n",
        "\n",
        "## **Batch Gradient Descent (BGD):** Uses the entire dataset to compute gradients.\n",
        "✅ Stable but slow.\n",
        "❌ Not suitable for large datasets.\n",
        "Stochastic Gradient Descent (SGD): Updates parameters using one sample at a time.\n",
        "✅ Faster than BGD.\n",
        "❌ Noisy convergence.\n",
        "Mini-Batch Gradient Descent: Uses a small batch of samples for updates.\n",
        "✅ Balances efficiency & accuracy.\n",
        "Example in Python:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "optimizer = SGD(learning_rate=0.01)\n",
        "(b) Momentum-Based Optimization\n",
        "Introduces a momentum term to accelerate convergence and reduce oscillations.\n",
        "Formula:\n",
        "\n",
        "𝑣\n",
        "𝑡\n",
        "=\n",
        "𝛽\n",
        "𝑣\n",
        "𝑡\n",
        "−\n",
        "1\n",
        "+\n",
        "(\n",
        "1\n",
        "−\n",
        "𝛽\n",
        ")\n",
        "∇\n",
        "𝐽\n",
        "(\n",
        "𝜃\n",
        ")\n",
        "v\n",
        "t\n",
        "​\n",
        " =βv\n",
        "t−1\n",
        "​\n",
        " +(1−β)∇J(θ)\n",
        "𝜃\n",
        "=\n",
        "𝜃\n",
        "−\n",
        "𝛼\n",
        "𝑣\n",
        "𝑡\n",
        "θ=θ−αv\n",
        "t\n",
        "​\n",
        "\n",
        "Example in Python:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
        "✅ Pros: Faster convergence than vanilla SGD\n",
        "❌ Cons: May overshoot if momentum is too high\n",
        "\n",
        "2. Second-Order Optimization Algorithms (Hessian-Based)\n",
        "These optimizers use second-order derivatives (Hessian matrix) to adjust learning rates.\n",
        "\n",
        "(a) Newton’s Method\n",
        "Uses the Hessian matrix to adjust learning rates dynamically.\n",
        "Formula:\n",
        "\n",
        "𝜃\n",
        "=\n",
        "𝜃\n",
        "−\n",
        "𝐻\n",
        "−\n",
        "1\n",
        "∇\n",
        "𝐽\n",
        "(\n",
        "𝜃\n",
        ")\n",
        "θ=θ−H\n",
        "−1\n",
        " ∇J(θ)\n",
        "✅ Pros: More precise updates\n",
        "❌ Cons: Computationally expensive\n",
        "\n",
        "3. Adaptive Learning Rate Optimizers\n",
        "These adjust the learning rate dynamically for better convergence.\n",
        "\n",
        "(a) AdaGrad (Adaptive Gradient)\n",
        "Assigns different learning rates to different parameters based on past gradients.\n",
        "✅ Pros: Works well for sparse data.\n",
        "❌ Cons: Learning rate decreases aggressively over time.\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "from tensorflow.keras.optimizers import Adagrad\n",
        "optimizer = Adagrad(learning_rate=0.01)\n",
        "(b) RMSprop (Root Mean Square Propagation)\n",
        "Uses moving averages of squared gradients for adaptive learning rates.\n",
        "Works well for deep networks and RNNs.\n",
        "✅ Pros: Effective in non-stationary problems.\n",
        "❌ Cons: Sensitive to hyperparameters.\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "optimizer = RMSprop(learning_rate=0.001)\n",
        "(c) Adam (Adaptive Moment Estimation)\n",
        "Combines Momentum & RMSprop for efficient updates.\n",
        "The most widely used optimizer in deep learning.\n",
        "✅ Pros: Works well in most cases.\n",
        "❌ Cons: May generalize poorly in some problems.\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "(d) AdaDelta\n",
        "A refined version of AdaGrad that does not decay learning rates aggressively.\n",
        "✅ Pros: No need for an initial learning rate.\n",
        "❌ Cons: May be slower in some cases.\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "optimizer = Adadelta(learning_rate=1.0)\n",
        "4. Derivative-Free Optimization\n",
        "Used when gradient information is unavailable.\n",
        "\n",
        "(a) Genetic Algorithms (GA)\n",
        "Inspired by natural selection, it evolves solutions over generations.\n",
        "✅ Pros: Works for non-differentiable functions.\n",
        "❌ Cons: Computationally expensive.\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "from geneticalgorithm import geneticalgorithm as ga\n",
        "(b) Particle Swarm Optimization (PSO)\n",
        "Inspired by swarm behavior (e.g., birds flocking).\n",
        "✅ Pros: Good for global optimization.\n",
        "❌ Cons: May get stuck in local optima.\n",
        "\n"
      ],
      "metadata": {
        "id": "05SZFhnmv3tB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **17.What is sklearn.linear_model ?**"
      ],
      "metadata": {
        "id": "KHDlTzczx65C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The sklearn.linear_model module in Scikit-Learn provides different types of linear models for regression and classification tasks. These models assume a linear relationship between input features and the target variable."
      ],
      "metadata": {
        "id": "L_OgTEL2yI1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **18. What does model.fit() do? What arguments must be given?**"
      ],
      "metadata": {
        "id": "y29TcUw0yNxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The **.fit()** method in Scikit-Learn (or other ML libraries like TensorFlow/Keras) is used to train (fit) a model on given data. It learns the relationship between input features (X) and target labels (y) by adjusting the model parameters.\n",
        "\n",
        "## **Arguments for model.fit()**\n",
        "## **X (Input Features):**\n",
        "\n",
        "## A 2D array (numpy.ndarray, pandas.DataFrame, etc.).\n",
        "## Shape: (n_samples, n_features).\n",
        "## **y (Target Labels):**\n",
        "\n",
        "## A 1D or 2D array (numpy.ndarray, pandas.Series, etc.).\n",
        "## Shape: (n_samples,) for single target, (n_samples, n_targets) for multiple targets.\n",
        "## **Additional Parameters (Optional, depending on model):**\n",
        "\n",
        "## sample_weight: Weights for samples (useful for imbalanced data).\n",
        "## epochs: For deep learning models (number of training iterations).\n",
        "## batch_size: Number of samples per gradient update (for deep learning).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w9bSwtL8yYWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **19. What does model.predict() do? What arguments must be given?**"
      ],
      "metadata": {
        "id": "pxTSeeh5zeN7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The .predict() method in machine learning models is used to make predictions on new/unseen data after the model has been trained using .fit().\n",
        "\n",
        "## It takes input features (X) and outputs predicted values (y_pred).\n",
        "## The type of prediction depends on the model:\n",
        "## Regression models → Predict continuous values.\n",
        "## Classification models → Predict class labels or probabilities.\n",
        "\n",
        "## **Arguments for model.predict()**\n",
        "## **X (Input Features) → Required**\n",
        "\n",
        "## A 2D array (numpy.ndarray, pandas.DataFrame, etc.).\n",
        "## Shape: (n_samples, n_features).\n",
        "## Additional Arguments (Optional, depending on the model):\n",
        "\n",
        "## batch_size: (For deep learning) Number of samples processed at a time.\n",
        "## verbose: (For deep learning) Controls logging output during prediction.\n"
      ],
      "metadata": {
        "id": "C3jsuWkRzbGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **20. What are continuous and categorical variables?**"
      ],
      "metadata": {
        "id": "wn2AKGJs0A_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Continuous Variables**\n",
        "## **Definition:** Continuous variables can take any numerical value within a range.\n",
        "## Characteristics:\n",
        "## Can have decimals (e.g., 1.5, 2.75).\n",
        "## Measured, not counted.\n",
        "## Infinite possible values.\n",
        "\n",
        "## **Categorical Variables**\n",
        "## **Definition:** Categorical variables represent groups or categories.\n",
        "## Characteristics:\n",
        "## Cannot have decimal values.\n",
        "## Limited, fixed number of values.\n",
        "## Data is classified into groups."
      ],
      "metadata": {
        "id": "wERruCT00FrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **21. What is feature scaling? How does it help in Machine Learning?**"
      ],
      "metadata": {
        "id": "iB4sY1cS0vWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature scaling is the process of normalizing or standardizing the range of independent variables (features) in a dataset. It ensures that all features contribute equally to the model, preventing bias due to different scales.\n",
        "\n",
        "## **Improves Model Performance**\n",
        "\n",
        "## Many ML algorithms (e.g., gradient descent, SVM, KNN) work better when features are on a similar scale.\n",
        "## **Avoids Dominance of Large Values**\n",
        "\n",
        "## Example: If we have height (in cm) and salary (in thousands), the model may give more importance to salary just because the numbers are larger.\n",
        "## **Speeds Up Convergence in Gradient Descent**\n",
        "\n",
        "## If features are on vastly different scales, optimization algorithms like Gradient Descent take longer to converge.\n",
        "## **Improves Distance-Based Algorithms**\n",
        "\n",
        "## Algorithms like KNN, K-Means, SVM use distance metrics (e.g., Euclidean distance). Scaling prevents features with larger magnitudes from dominating calculations."
      ],
      "metadata": {
        "id": "gF-QuXCL05B1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **22.How do we perform scaling in Python?**"
      ],
      "metadata": {
        "id": "JaRFSfwa3m-e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Min-Max Scaling (Normalization)**\n",
        " ## Scaled range: [0, 1] (or [-1, 1] if specified).\n",
        "## Best for: Algorithms that assume bounded values (e.g., Neural Networks, KNN)."
      ],
      "metadata": {
        "id": "kM34MW1X1kJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([[100], [200], [300], [400], [500]])\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(X_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp8iqy4omc6_",
        "outputId": "27d547a9-9c35-4163-b056-3c43467a2a64"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.  ]\n",
            " [0.25]\n",
            " [0.5 ]\n",
            " [0.75]\n",
            " [1.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Standardization (Z-score Normalization)**\n",
        "Formula:\n",
        "𝑋\n",
        "′\n",
        "=\n",
        "𝑋\n",
        "−\n",
        "𝜇\n",
        "/\n",
        "𝜎\n",
        "\n",
        "\n",
        "Where\n",
        "𝜇\n",
        "μ is the mean and\n",
        "𝜎\n",
        "σ is the standard deviation.\n",
        "Scaled range: Mean = 0, Standard Deviation = 1.\n",
        "Best for: Normally distributed data (e.g., Linear Regression, Logistic Regression, PCA)."
      ],
      "metadata": {
        "id": "33SPDMD31_bx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_standardized = scaler.fit_transform(X)\n",
        "\n",
        "print(X_standardized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gAkH8Nl19tA",
        "outputId": "51ca727c-d2a2-4022-f1fc-ad9ef181c5dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.41421356]\n",
            " [-0.70710678]\n",
            " [ 0.        ]\n",
            " [ 0.70710678]\n",
            " [ 1.41421356]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **23. What is sklearn.preprocessing?**"
      ],
      "metadata": {
        "id": "_zWl8M8o2w3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The sklearn.preprocessing module in Scikit-Learn provides a collection of functions and classes for transforming raw data into a format suitable for machine learning models."
      ],
      "metadata": {
        "id": "svV-zN6Y2xka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **24. How do we split data for model fitting (training and testing) in Python?**"
      ],
      "metadata": {
        "id": "Vdo4vf012-Nw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In machine learning, we need to split the dataset into training and testing sets to evaluate model performance properly. Scikit-Learn's train_test_split() function helps us do this easily.\n",
        "\n"
      ],
      "metadata": {
        "id": "7ijhhNpI3KpY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **25. Explain data encoding?**"
      ],
      "metadata": {
        "id": "84VIgKLw3Ofj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data encoding is the process of converting categorical data into numerical format so that machine learning models can understand and process it effectively. Since most ML algorithms work with numerical data, categorical variables (like \"Red\", \"Blue\", \"Green\") must be transformed into numbers."
      ],
      "metadata": {
        "id": "nzuV3X5K3aLW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ikEzydNj2mSM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}